{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368389dd",
   "metadata": {},
   "source": [
    "# Recognizing Handwritten Digits\n",
    "> Data analysis is not limited to numbers and strings, because images and sounds can also be analyzed and classified.\n",
    "Recognizing handwritten text is a problem that can be traced back to the first automatic machines that needed to recognize individual characters in handwritten documents. OCR software must read handwritten text, or pages of printed books, for general electronic documents in which each character is well defined.\n",
    "\n",
    "- toc:true- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: GaganKumar\n",
    "- categories: [DataAnalysis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a9771",
   "metadata": {},
   "source": [
    "## Introduction ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133ef55",
   "metadata": {},
   "source": [
    "**The scikit-learn library provides a good example to better understand this technique, the issues involved, and the \n",
    "possibility of making prediction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419e06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc843eb",
   "metadata": {},
   "source": [
    "**The scikit-learn library provides numerous datasets that are useful for testing many \n",
    "problems of data analysis and prediction of the results. Also in this case there is a dataset \n",
    "of images called Digits.\n",
    "Loading the digit dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353f235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01db42a4",
   "metadata": {},
   "source": [
    " **read lots of information about the datasets by calling the DESCR attribute.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c243fa3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad36633",
   "metadata": {},
   "source": [
    "**The images of the handwritten digits are contained in a digits.images array. Each \n",
    "element of this array is an image that is represented by an 8x8 matrix of numerical values \n",
    "that correspond to a grayscale from white, with a value of 0, to black, with the value 15.**\n",
    "\n",
    "**Example for digits.images[1]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0512bad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 11., 16.,  9.,  0.,  0.],\n",
       "        [ 0.,  0.,  3., 15., 16.,  6.,  0.,  0.],\n",
       "        [ 0.,  7., 15., 16., 16.,  2.,  0.,  0.],\n",
       "        [ 0.,  0.,  1., 16., 16.,  3.,  0.,  0.],\n",
       "        [ 0.,  0.,  1., 16., 16.,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  1., 16., 16.,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 11., 16., 10.,  0.,  0.]]),\n",
       " (8, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[1], digits.images[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919ff9f6",
   "metadata": {},
   "source": [
    "**You can visually check the contents of this result using the matplotlib library,**\n",
    "**By launching this command, you will obtain the grayscale image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2193c1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4fc8125990>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[1], cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe1352d",
   "metadata": {},
   "source": [
    "**Numerical values represented by images, i.e., the targets, are contained in the \n",
    "digit.targets array.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d475ae58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fc6090",
   "metadata": {},
   "source": [
    "**It was reported that the dataset is a training set consisting of 1,797 images. You can \n",
    "determine if that is true**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "668e787a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba5e15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 8, 8), (1797,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images.shape, digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d24025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, H, W = digits.images.shape\n",
    "N, H, W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9719c4c1",
   "metadata": {},
   "source": [
    "**Inputs to the model should be of shape `No. of samples * No. of features`.**\n",
    "\n",
    "**So our digits inputs should be reshaped from `1797 * 8 * 8` to `1797 * 64`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4feb0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images = digits.images.reshape(N, (H * W))\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86cfc0",
   "metadata": {},
   "source": [
    "**train_test_split is used to split the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c71e5",
   "metadata": {},
   "source": [
    "**Step 1-Splitting the data in to 80 percent and 20 percent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ef2f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (360, 64), (1437,), (360,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(digits.images, digits.target, test_size=0.2)\n",
    "train_X.shape, val_X.shape, train_y.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ca7f8",
   "metadata": {},
   "source": [
    "**Firstly we create the RF model and fit model to train data,predict the train data using trained model,predict\n",
    "on valid data using trained model printing the accuracy scores for both train and valid data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2acd262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Valid accuracy: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "# create RF model\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "# fit model to train data\n",
    "model.fit(train_X, train_y)\n",
    "# predict on train data using trained model\n",
    "train_pred = model.predict(train_X)\n",
    "# predict on valid data using trained model\n",
    "val_pred = model.predict(val_X)\n",
    "# print accuracy scores for both train and valid data\n",
    "print(f\"Train accuracy: {accuracy_score(train_y, train_pred)}\")\n",
    "print(f\"Valid accuracy: {accuracy_score(val_y, val_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9a582",
   "metadata": {},
   "source": [
    "**Step-2 Splitting the data in to 70 percent and 30 percent and predicting the accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68b7da25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1257, 64), (540, 64), (1257,), (540,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(digits.images, digits.target, test_size=0.3)\n",
    "train_X.shape, val_X.shape, train_y.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b3f6471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Valid accuracy: 0.9703703703703703\n"
     ]
    }
   ],
   "source": [
    "# create RF model\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "# fit model to train data\n",
    "model.fit(train_X, train_y)\n",
    "# predict on train data using trained model\n",
    "train_pred = model.predict(train_X)\n",
    "# predict on valid data using trained model\n",
    "val_pred = model.predict(val_X)\n",
    "# print accuracy scores for both train and valid data\n",
    "print(f\"Train accuracy: {accuracy_score(train_y, train_pred)}\")\n",
    "print(f\"Valid accuracy: {accuracy_score(val_y, val_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d915644",
   "metadata": {},
   "source": [
    "**Step-3 Splitting the data in to 60 percent and 40 percent and predicting the accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9de92033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1078, 64), (719, 64), (1078,), (719,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(digits.images, digits.target, test_size=0.4)\n",
    "train_X.shape, val_X.shape, train_y.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33ea7d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Valid accuracy: 0.9763560500695411\n"
     ]
    }
   ],
   "source": [
    "# create RF model\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "# fit model to train data\n",
    "model.fit(train_X, train_y)\n",
    "# predict on train data using trained model\n",
    "train_pred = model.predict(train_X)\n",
    "# predict on valid data using trained model\n",
    "val_pred = model.predict(val_X)\n",
    "# print accuracy scores for both train and valid data\n",
    "print(f\"Train accuracy: {accuracy_score(train_y, train_pred)}\")\n",
    "print(f\"Valid accuracy: {accuracy_score(val_y, val_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da6272f",
   "metadata": {},
   "source": [
    "## Conclusion ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2340f",
   "metadata": {},
   "source": [
    "**We can clearly say that in all the 3 steps the accuracy of our model is more than 95 percent,\n",
    "hence the hypothesis is accepted**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d5375",
   "metadata": {},
   "source": [
    "#### \"I am thankful to mentors at https://internship.suvenconsultants.com for providing awesome problem statements and giving many of us a Coding Internship Exprience. Thank you www.suvenconsultants.com\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
